// OpenAI Text-to-Speech Service
export class TextToSpeechService {
  constructor(apiKey) {
    this.apiKey = apiKey
    this.baseUrl = 'https://api.openai.com/v1/audio/speech'
    this.audioContext = null
    this.currentAudio = null
  }

  /**
   * Convert text to speech using OpenAI TTS
   * @param {string} text - Text to convert to speech
   * @param {Object} options - TTS options
   * @returns {Promise<void>} - Plays the audio
   */
  async speakText(text, options = {}) {
    try {
      console.log('üîä Converting text to speech:', text)

      const requestBody = {
        model: options.model || 'tts-1', // tts-1 is faster, tts-1-hd is higher quality
        input: text,
        voice: options.voice || 'alloy', // alloy, echo, fable, onyx, nova, shimmer
        response_format: options.format || 'mp3',
        speed: options.speed || 1.0 // 0.25 to 4.0
      }

      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(`TTS API error: ${response.status} ${errorData.error?.message || response.statusText}`)
      }

      // Get audio data as array buffer
      const audioData = await response.arrayBuffer()
      
      // Play the audio
      await this.playAudioBuffer(audioData)
      
      console.log('‚úÖ Text-to-speech completed')
    } catch (error) {
      console.error('‚ùå Text-to-speech error:', error)
      throw error
    }
  }

  /**
   * Play audio buffer
   * @param {ArrayBuffer} audioData - Audio data to play
   */
  async playAudioBuffer(audioData) {
    try {
      // Stop current audio if playing
      this.stopCurrentAudio()

      // –î–ª—è iPhone - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π HTML5 Audio –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –¥–∏–Ω–∞–º–∏–∫–∞–º–∏
      if (this.isiOS()) {
        return await this.playAudioBufferIOS(audioData)
      }

      // Create audio context if not exists
      if (!this.audioContext) {
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)()
      }

      // Resume audio context if suspended (required by browser policies)
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume()
      }

      // Create audio buffer from data
      const audioBuffer = await this.audioContext.decodeAudioData(audioData)
      
      // Create and configure buffer source
      const source = this.audioContext.createBufferSource()
      source.buffer = audioBuffer
      
      // –î–ª—è –ª—É—á—à–µ–≥–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö
      const gainNode = this.audioContext.createGain()
      gainNode.gain.value = 1.0
      
      source.connect(gainNode)
      gainNode.connect(this.audioContext.destination)
      
      // Store reference for stopping
      this.currentAudio = source
      
      // Play audio
      source.start(0)
      
      // Clean up when finished
      return new Promise((resolve) => {
        source.onended = () => {
          this.currentAudio = null
          resolve()
        }
      })
    } catch (error) {
      console.error('Error playing audio:', error)
      throw error
    }
  }

  /**
   * Play audio buffer specifically for iOS devices
   * @param {ArrayBuffer} audioData - Audio data to play
   */
  async playAudioBufferIOS(audioData) {
    return new Promise((resolve, reject) => {
      try {
        // –°–æ–∑–¥–∞–µ–º Blob –∏–∑ ArrayBuffer
        const audioBlob = new Blob([audioData], { type: 'audio/mp3' })
        const audioUrl = URL.createObjectURL(audioBlob)
        
        // –°–æ–∑–¥–∞–µ–º HTML5 Audio —ç–ª–µ–º–µ–Ω—Ç
        const audio = new Audio(audioUrl)
        
        // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è iPhone
        audio.preload = 'auto'
        audio.volume = 1.0
        
        // –ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤—ã—Ö–æ–¥—ã
        if (audio.setSinkId) {
          // –ï—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤—ã–±–æ—Ä –∞—É–¥–∏–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º default
          audio.setSinkId('default').catch(() => {
            console.log('setSinkId not supported, using default output')
          })
        }
        
        this.currentAudio = audio
        
        audio.onended = () => {
          URL.revokeObjectURL(audioUrl)
          this.currentAudio = null
          resolve()
        }
        
        audio.onerror = (error) => {
          URL.revokeObjectURL(audioUrl)
          this.currentAudio = null
          reject(error)
        }
        
        // –ó–∞–ø—É—Å–∫ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        audio.play().catch(reject)
        
      } catch (error) {
        reject(error)
      }
    })
  }

  /**
   * Detect if running on iOS
   * @returns {boolean}
   */
  isiOS() {
    return /iPad|iPhone|iPod/.test(navigator.userAgent) || 
           (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1)
  }

  /**
   * Stop current audio playback
   */
  stopCurrentAudio() {
    if (this.currentAudio) {
      try {
        // –î–ª—è HTML5 Audio –∏—Å–ø–æ–ª—å–∑—É–µ–º pause() –∏ reset
        if (this.currentAudio.pause) {
          this.currentAudio.pause()
          this.currentAudio.currentTime = 0
        } else {
          // –î–ª—è AudioContext –∏—Å–ø–æ–ª—å–∑—É–µ–º stop()
          this.currentAudio.stop()
        }
        this.currentAudio = null
      } catch (error) {
        console.warn('Error stopping audio:', error)
        this.currentAudio = null
      }
    }
  }

  /**
   * Check if TTS is currently playing
   * @returns {boolean}
   */
  isSpeaking() {
    if (!this.currentAudio) return false
    
    // –î–ª—è HTML5 Audio –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
    if (this.currentAudio.paused !== undefined) {
      return !this.currentAudio.paused && !this.currentAudio.ended
    }
    
    // –î–ª—è AudioContext –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—ä–µ–∫—Ç–∞
    return true
  }

  /**
   * Get available voices for TTS
   * @returns {Array<string>} - List of available voice names
   */
  static getAvailableVoices() {
    return ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']
  }

  /**
   * Get available models for TTS
   * @returns {Array<string>} - List of available model names
   */
  static getAvailableModels() {
    return ['tts-1', 'tts-1-hd']
  }
}