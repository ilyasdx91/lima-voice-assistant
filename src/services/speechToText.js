// OpenAI Whisper Speech-to-Text Service
import medicineTerms from '@/data/medicine-terms.json'

export class SpeechToTextService {
  constructor(apiKey) {
    this.apiKey = apiKey
    this.baseUrl = 'https://api.openai.com/v1/audio/transcriptions'
  }

  /**
   * Convert audio blob to text using OpenAI Whisper
   * @param {Blob} audioBlob - The audio data to transcribe
   * @param {Object} options - Additional options
   * @returns {Promise<string>} - The transcribed text
   */
  async transcribeAudio(audioBlob, options = {}) {
    try {
      // Prepare FormData for the API request
      const formData = new FormData()
      
      // Convert blob to file with proper extension for Whisper
      let fileName = 'audio.webm'
      let mimeType = 'audio/webm'
      
      // Determine file format based on blob type
      if (audioBlob.type.includes('mp4')) {
        fileName = 'audio.mp4'
        mimeType = 'audio/mp4'
      } else if (audioBlob.type.includes('wav')) {
        fileName = 'audio.wav'
        mimeType = 'audio/wav'
      }
      
      const audioFile = new File([audioBlob], fileName, {
        type: mimeType
      })
      
      formData.append('file', audioFile)
      formData.append('model', 'whisper-1')
      formData.append('language', options.language || 'ru') // Russian by default
      formData.append('response_format', options.format || 'text')
      
      // –î–æ–±–∞–≤–ª—è–µ–º temperature –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
      formData.append('temperature', '0.0')
      
      // –°–æ–∑–¥–∞–µ–º prompt —Å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
      const prompt = this.createMedicalPrompt(options.prompt)
      if (prompt) {
        formData.append('prompt', prompt)
      }

      console.log('üîä Sending audio to Whisper API...')

      // Make API request
      const response = await fetch(this.baseUrl, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: formData
      })

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}))
        throw new Error(`Whisper API error: ${response.status} ${errorData.error?.message || response.statusText}`)
      }

      const result = await response.text()
      console.log('‚úÖ Transcription completed:', result)
      
      return result.trim()
    } catch (error) {
      console.error('‚ùå Speech-to-text error:', error)
      throw error
    }
  }

  /**
   * Get transcription with JSON response format (includes confidence, segments, etc.)
   * @param {Blob} audioBlob - The audio data to transcribe
   * @param {Object} options - Additional options
   * @returns {Promise<Object>} - Detailed transcription data
   */
  async transcribeAudioDetailed(audioBlob, options = {}) {
    const detailedOptions = {
      ...options,
      format: 'json'
    }
    
    const response = await this.transcribeAudio(audioBlob, detailedOptions)
    return JSON.parse(response)
  }

  /**
   * –°–æ–∑–¥–∞–µ—Ç prompt —Å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
   * @param {string} customPrompt - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π prompt
   * @returns {string} - –ì–æ—Ç–æ–≤—ã–π prompt –¥–ª—è Whisper
   */
  createMedicalPrompt(customPrompt = '') {
    // –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ 20 —Ç–µ—Ä–º–∏–Ω–æ–≤ –¥–ª—è prompt (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Whisper API)
    const randomTerms = medicineTerms
      .sort(() => 0.5 - Math.random())
      .slice(0, 20)
      .join(', ')
    
    const medicalContext = `–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã: ${randomTerms}.`
    
    return customPrompt ? `${medicalContext} ${customPrompt}` : medicalContext
  }

  /**
   * Validate API key format
   * @param {string} apiKey - OpenAI API key
   * @returns {boolean} - True if format is valid
   */
  static validateApiKey(apiKey) {
    return typeof apiKey === 'string' && apiKey.startsWith('sk-') && apiKey.length > 20
  }
}